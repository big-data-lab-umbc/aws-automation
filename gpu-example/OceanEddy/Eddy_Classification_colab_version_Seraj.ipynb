{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Eddy_Classification_colab_version_Seraj.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##This notebook can be used to classify the images with eddy from non-eddy using google colab platform."
      ],
      "metadata": {
        "id": "W4kko3Sko3r3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mount directories from google drive"
      ],
      "metadata": {
        "id": "XUlLoZHsosjD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUv9EvlV2dOO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import libraries"
      ],
      "metadata": {
        "id": "Yc0tPcvUor-r"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t-JTtbtjCCx"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ri0NPu8jsG2"
      },
      "source": [
        "data_dir = ('/content/drive/your/dir/')\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "print(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###From 3 channel RGB to 1 channel grayscale image conversion using Keras ImageDataGenerator. (Uncomment if needed)."
      ],
      "metadata": {
        "id": "yqEuxmUXp89p"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiMJO89BG4_w"
      },
      "source": [
        "# img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI54J1sDGzgt"
      },
      "source": [
        "# train_ds = tf.data.Dataset.from_generator(\n",
        "#     lambda: img_gen.flow_from_directory(data_dir, batch_size=32, shuffle=True),\n",
        "#     output_types=(tf.float32, tf.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9TvczG5SGpQ"
      },
      "source": [
        "# def convert_to_grayscale(image, label):\n",
        "#   return tf.image.rgb_to_grayscale(image), label ## check with actual image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P66-9GykG1PW"
      },
      "source": [
        "# images, _ = next(iter(train_ds.take(1)))\n",
        "# image = images[0]\n",
        "# print('Before conversion --> ', image.shape)\n",
        "\n",
        "# train_ds = train_ds.map(convert_to_grayscale)\n",
        "# images, _ = next(iter(train_ds.take(1)))\n",
        "\n",
        "# image = images[0]\n",
        "# print('After conversion --> ', image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###libraries"
      ],
      "metadata": {
        "id": "lJyzYPY3q8QG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ljMDYt7IIqsm"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import keras\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fap6urzIqsr"
      },
      "source": [
        "data_path = ('/content/drive/MyDrive/path/to/dir')\n",
        "img_path= data_path\n",
        "os.chdir(img_path)\n",
        "print(os.path.abspath(os.getcwd()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###libraries"
      ],
      "metadata": {
        "id": "YcIGCv9bq7T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "# import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "TQOQapEwqrRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65hJ37VTIqss"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(8, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "plot_model(model, to_file='model_plot11.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu9wo85vIqss"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# # this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=False) ## cannot do flip\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(\n",
        "        rescale=1./255)\n",
        "\n",
        "# this is a generator that will read pictures found in\n",
        "# subfolers of 'data/train', and indefinitely generate\n",
        "# batches of augmented image data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/your/dir',  # this is the target directory\n",
        "        target_size=(256, 256),  # all images will be resized to 150x150\n",
        "        color_mode = 'grayscale',\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
        "\n",
        "# this is a similar generator, for validation data\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/your/dir',\n",
        "        target_size=(256, 256),\n",
        "        color_mode = 'grayscale',\n",
        "        batch_size=1,\n",
        "        class_mode='binary')\n",
        "\n",
        "# this is a similar generator, for validation data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/your/dir',\n",
        "        target_size=(256, 256),\n",
        "        color_mode = 'grayscale',\n",
        "        batch_size=1,\n",
        "        class_mode=None,\n",
        "        shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zti3cZ_HIqst"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwSnTCu-Iqsu"
      },
      "source": [
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=200 // batch_size,\n",
        "        epochs=5,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=80 // batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqkYHl6eIqsv"
      },
      "source": [
        "nb_test_samples = 15\n",
        "probabilities_temp = model.predict_generator(test_generator, nb_test_samples)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy.special import expit\n",
        "\n",
        "probabilities = expit(probabilities_temp)\n",
        "\n",
        "y_true = np.array([0] * 13 + [1] * 2)\n",
        "y_pred = probabilities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUC05fSmIqsw"
      },
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "average_precision = average_precision_score(y_true, y_pred)\n",
        "average_precision"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}